{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from LSTM_training import LSTM_Model, SeqDataset, create_windows\n",
    "\n",
    "\n",
    "PATH = 'best_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the test data (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = ['Zweirad', 'Personenwagen', 'Lastwagen', 'Hr', 'RainDur', 'T', 'WVs', 'StrGlo', 'p', \"AQI\"] \n",
    "y_label = \"AQI\"\n",
    "\n",
    "data = pd.read_csv('../processed_data/full_data_imputed_with_EAQI.csv')\n",
    "\n",
    "data = data.loc[data[\"Jahr\"]== 2021]\n",
    "\n",
    "X_data = data[X_labels]\n",
    "y_data = data[y_label]\n",
    "X, y = create_windows(X_data, y_data, 48)\n",
    "\n",
    "test_data = SeqDataset(X, y)\n",
    "\n",
    "loaded_data = DataLoader(test_data, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Luca\\Data_Science_Project\\LSTM\\Plots_Luca.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Luca/Data_Science_Project/LSTM/Plots_Luca.ipynb#ch0000003?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LSTM_Model()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luca/Data_Science_Project/LSTM/Plots_Luca.ipynb#ch0000003?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(PATH))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Luca/Data_Science_Project/LSTM/Plots_Luca.ipynb#ch0000003?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mdouble)\n",
      "File \u001b[1;32mc:\\Users\\Luca\\Data_Science_Project\\LSTM\\LSTM_training.py:145\u001b[0m, in \u001b[0;36mLSTM_Model.__init__\u001b[1;34m(self, hidden_size, num_layers)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=141'>142</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m hidden_size\n\u001b[0;32m    <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=143'>144</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=144'>145</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLSTM(input_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_labels), hidden_size\u001b[39m=\u001b[39mhidden_size,\n\u001b[0;32m    <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=145'>146</a>\u001b[0m                   num_layers\u001b[39m=\u001b[39mnum_layers, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dropout\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=146'>147</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m, \u001b[39m5\u001b[39m) \n\u001b[0;32m    <a href='file:///c%3A/Users/Luca/Data_Science_Project/LSTM/LSTM_training.py?line=148'>149</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_labels' is not defined"
     ]
    }
   ],
   "source": [
    "model = LSTM_Model()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model = model.to(torch.double)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for j, (xi, yi) in enumerate(loaded_data):\n",
    "        y_predicted = model(xi)\n",
    "        y_pred.append(np.argmax(y_predicted.numpy()))\n",
    "        y_true.append(np.argmax(yi.numpy()))\n",
    "\n",
    "# with open('saved_stats.pkl', 'rb') as f:\n",
    "#     stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f105814abe7722c949ed84f2cf4bc50ddbb20218e6eec96fb73f630dc63afebf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
